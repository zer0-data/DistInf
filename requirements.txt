torch>=2.2.0
transformers>=4.38.0
datasets>=2.18.0  # For babilong test dataset
numpy>=1.26.0
tqdm>=4.66.0
accelerate>=0.27.0
scikit-learn>=1.4.0  # Required for k-means summarization (run_single_sample.py)

# Optional: For flash attention support in some components
# Install with: pip install flash-attn --no-build-isolation
flash-attn>=2.5.0